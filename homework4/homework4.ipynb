{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOSx92DfO-cg"
   },
   "source": [
    "# CS 344: Homework 4\n",
    "## Elizabeth Koning\n",
    "### April 12, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "841UulnIO-cj"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "The advantage that NN have over perceptrons is on the XOR problem. Perceptrons were unable to represent the exclusive or, but neural networks can. This means that it doesn't have such a major gap in its potential.\n",
    "\n",
    "The advantage that neural networks have over expert systems is with the issues of rules. A neural network can take in the data, while an expert system would quickly become overwhelming with its extensive and even contradictory rules. For example, the MYCIL addressing bacterial infection was one of the expert systems that stopped working when they got to 2000 rules.\n",
    "\n",
    "The biggest issue that NN have right now is with explainability. Deep neural networks are able to make predictions, but they can't explain why something is the case. Like Prof. Vander Linden was talking about in class and quoting Fred Jelinek, the more statistical the models get, the more accurate they become. However, it is also true that we understand them less and less. One of the issues that researchers are thinking about now is the explainability. As more scientists (including biologists) are utilizing AI, they are looking for different kinds of usability and answers than the computer scientists are.\n",
    "\n",
    "When we shifted from GOFAI to Bayesian statistics, ML, and NN, this marked a shift from focusing on the process getting to the result, to getting to the results themselves. However, at some point we will want to move back to understand the process of coming to conclusions. While we can answer many questions with strategies that make predictions the way neural networks do, it does not address all problems. I think that neural networks will remain a piece of that, but I also think that there will be unrelated future breakthroughs to address problems from a different direction and obtain different answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkQ33hJtO-ck",
    "pycharm": {}
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "(started from the example in class)\n",
    "\n",
    "1. Fill in random weights.\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    &\\begin{bmatrix}\n",
    "    w_{i_1,h_1} & w_{i_1,h_2} \\\\\n",
    "    w_{i_2,h_1} & w_{i_2,h_2}\n",
    "    \\end{bmatrix}\n",
    "    \\leftarrow\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} \\\\\n",
    "    &\\begin{bmatrix}\n",
    "    w_{h_1, o_1} \\\\ \n",
    "    w_{h_2, o_1} \n",
    "    \\end{bmatrix}\n",
    "    \\leftarrow\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\\n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\end{aligned}$\n",
    "    \n",
    "2. Compute the output for one sample (XOR: `[1, 1]` &rarr; `0`).\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    o_j &= \n",
    "    \\begin{bmatrix}\n",
    "    1 & 1 \\\\ \n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\\n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    1 * 0.11 + 1 * 0.21 & 1 * 0.12 + 1 * 0.08\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.32 & 0.20\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.32 * 0.14 + 0.20 * 0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &= 0.0748 \n",
    "    \\end{aligned}\n",
    "    \\\\\n",
    "    $\n",
    "\n",
    "3. Compute the error (and more importantly, the delta).\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    L_2Error &= (1 - 0.0748)^2 \\\\\n",
    "    &= 0.0.0056 \\\\\n",
    "    \\Delta_{o_1} &= (1 - 0.0748) \\\\\n",
    "    &= -0.0748 \\\\\n",
    "    \\end{aligned}$\n",
    "\n",
    "4. Backpropagate updates back through the network, assuming:\n",
    "    $learning\\_rate = 0.05$; \n",
    "    $f(x) = x$ activation functions for all nodes.\n",
    "     \n",
    "    $\\begin{aligned}\n",
    "    \\begin{bmatrix}\n",
    "    w_{h_1, o_1} \\\\ \n",
    "    w_{h_2, o_1}\n",
    "    \\end{bmatrix} &\\leftarrow \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} + 0.05 \\cdot \n",
    "    \\begin{bmatrix}\n",
    "    0.32 \\\\ \n",
    "    0.20 \n",
    "    \\end{bmatrix} \\cdot 1.0 \\cdot -0.0748 \\\\\\\\\n",
    "    &= \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * 0.32 * 1.0 * -0.0748 \\\\\n",
    "    0.05 * 0.20 * 1.0 * -0.0748 \n",
    "    \\end{bmatrix} \\\\\n",
    "    &= \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} +\n",
    "    \\begin{bmatrix}\n",
    "    -0.0012 \\\\\n",
    "    -0.0008 \n",
    "    \\end{bmatrix} \\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.1388 \\\\ \n",
    "    0.1492\n",
    "    \\end{bmatrix}\n",
    "    \\end{aligned}$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    \\begin{bmatrix}\n",
    "    w_{i_1,h_1} & w_{i_1,h_2} \\\\ \n",
    "    w_{i_2,h_1} & w_{i_2,h_2}\n",
    "    \\end{bmatrix} &\\leftarrow \n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + 0.05 \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    1 & 1 \\\\ \n",
    "    1 & 1\n",
    "    \\end{bmatrix} \\cdot 1.0 \\odot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 & 0.15 \\\\ \n",
    "    0.14 & 0.15\n",
    "    \\end{bmatrix} \\cdot -0.0748 \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "    0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "    \\end{bmatrix} \\odot \n",
    "    \\begin{bmatrix}\n",
    "    0.14 * -0.0748 & 0.15 * -0.0748\\\\ \n",
    "    0.14 * -0.0748 & 0.15 * -0.0748 \n",
    "    \\end{bmatrix} \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 & 0.05 \\\\ \n",
    "    0.05 & 0.05 \n",
    "    \\end{bmatrix} \\odot \n",
    "    \\begin{bmatrix}\n",
    "    -0.0105 & -0.0112 \\\\\n",
    "    -0.0105 & -0.0112\n",
    "    \\end{bmatrix} \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * -0.0105 & 0.05 * -0.0112 \\\\\n",
    "    0.05 * -0.0105 & 0.05 * -0.0112\n",
    "    \\end{bmatrix} \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} +     \n",
    "    \\begin{bmatrix}\n",
    "    -0.000525 & -0.00056 \\\\\n",
    "    -0.000525 & -0.00056\n",
    "    \\end{bmatrix} \\\\ &= \n",
    "    \\begin{bmatrix}\n",
    "    0.109475 & 0.11944 \\\\\n",
    "    0.209475 & 0.07944\n",
    "    \\end{bmatrix}  \n",
    "    \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wFxQtcIO-cn"
   },
   "source": [
    "### Problem 3: Build a Keras-based ConvNet for Kerasâ€™s Fashion MNIST dataset (fashion_mnist). Experiment with different network architectures, submit your most performant network, and report the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPlbNLB-O-cp"
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "TODO\n",
    "\n",
    "First, we import the fashion_mnist dataset and split it into training and testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "0OBBJjW-O-cr",
    "outputId": "0e6b1a2f-5737-4d53-e9dc-b97e83dd9916"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqgrPuOKO-c0"
   },
   "source": [
    "Now we can take a look at the shape of the data. From the documentation, we know that it is a dataset of 60,000 28x28 grayscale images of fashion categories, plus a test set of 10,000 images. There are 10 categories of different types of clothing that are included.\n",
    "\n",
    "The printout of the description confirms this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ZKS4JxnfO-c2",
    "outputId": "220c110b-8e67-425e-e336-e1ce4ca36fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images         \n",
      "\tcount: 60000         \n",
      "\tshape: (60000, 28, 28)         \n",
      "\timage data type: uint8         \n",
      "\tlabel data type: uint8 \n",
      " testing images         \n",
      "\tcount: 10000         \n",
      "\tshape: (10000, 28, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'training images \\\n",
    "        \\n\\tcount: {} \\\n",
    "        \\n\\tshape: {} \\\n",
    "        \\n\\timage data type: {} \\\n",
    "        \\n\\tlabel data type: {} \\n'.format(len(train_labels), train_images.shape, train_images.dtype, train_labels.dtype),\n",
    "    'testing images \\\n",
    "        \\n\\tcount: {} \\\n",
    "        \\n\\tshape: {}\\n'.format(len(test_labels), test_images.shape),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "BMnBD__uO-c9"
   },
   "source": [
    "Since the fashion_mnist dataset is similar in shape and dataypes to the mnist digit dataset, we can perform similar processing and reshaping before we send it into the network.\n",
    "\n",
    "Before running the model, we want to shape the images properly and convert the labels to be treated properly as categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_9K7HvJO-c-"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "rK9Eg0C-O-dD",
    "outputId": "520189d3-e8ae-4fde-dac5-68744fcccf1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "TcJFYbvzO-dK",
    "outputId": "c981b36f-566c-4f14-f18b-db27036c6027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5592 - acc: 0.7914\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.3466 - acc: 0.8736\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2921 - acc: 0.8924\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2593 - acc: 0.9041\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2344 - acc: 0.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc692e51198>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LkVjc7myP9F5",
    "outputId": "aa37b832-87c1-4065-fb28-66b72414cac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 340us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29801375185847284, 0.8954]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JVKkz8exw0JP"
   },
   "source": [
    "I also tried changing the middle layer to use 128 instead of 64, but that did not work as well.\n",
    "\n",
    "Here's another model with the loss changed to binary_crosentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "N45jzv0mwv-C",
    "outputId": "492473e5-6a80-4579-c6ad-ba6ca88c546d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1454 - acc: 0.9201\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0987 - acc: 0.9231\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0857 - acc: 0.9210\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0766 - acc: 0.9204\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0712 - acc: 0.9194\n",
      "10000/10000 [==============================] - 4s 392us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08747028469443321, 0.9142099809646607]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y99rNhOE2a1t"
   },
   "source": [
    "Using binary_crossentropy inproved the accuracy and loss for the model.\n",
    "\n",
    "Next, I changed the optimizer to sgd, still using binary_crossentorpy for the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "5T3entdA2Asj",
    "outputId": "3357f8c8-c991-4329-e1fe-df6828c68370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.3417 - acc: 0.8679\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 1.3749 - acc: 0.8528\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 3.6457 - acc: 0.7562\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 2.8854 - acc: 0.8100\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 2.8854 - acc: 0.8100\n",
      "10000/10000 [==============================] - 4s 388us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8854428779602053, 0.8099999994277954]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Dy07HZ35_6R"
   },
   "source": [
    "Using the sgd optimizer ended up making it much worse.\n",
    "\n",
    "Next, I'm seeing what happens if I add another dense layer of 64 after the flattening of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "9hfqgZRe6Dzc",
    "outputId": "5ab3f8f4-5e62-4349-c0c5-b7b444f336d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 97,482\n",
      "Trainable params: 97,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1472 - acc: 0.9182\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0949 - acc: 0.9230\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0819 - acc: 0.9238\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0772 - acc: 0.9231\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0697 - acc: 0.9229\n",
      "10000/10000 [==============================] - 4s 411us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09194183296263218, 0.9136899770736694]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agxRmLX77MJD"
   },
   "source": [
    "Adding that layer didn't make a huge difference, so next I'm going to try with using mean_squared_error for the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "DhwCESBP78eY",
    "outputId": "bc380404-b291-4c94-8495-cda50cd53a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0367 - acc: 0.7634\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0202 - acc: 0.8740\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0166 - acc: 0.8936\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0147 - acc: 0.9052\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0133 - acc: 0.9138\n",
      "10000/10000 [==============================] - 4s 427us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01500041814595461, 0.9048]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KobpFwvJBqlw"
   },
   "source": [
    "Using mean squared error gives it a better shape of improvement from the first to last epoch, but the final result is worse.\n",
    "\n",
    "Next, I want to try making changes to the parameters on fit. Because the mean_squared error shows so much improvement over the epochs, I want to see what it does with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 0.0356 - acc: 0.7710\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0196 - acc: 0.8755 - ETA: 0s - loss: 0.0197 - ac\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 55s 920us/step - loss: 0.0160 - acc: 0.8973- ETA: 4s - loss: 0.0161 - acc -  -\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 51s 842us/step - loss: 0.0142 - acc: 0.9082\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 0.0129 - acc: 0.9165\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 55s 921us/step - loss: 0.0119 - acc: 0.9232\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 55s 924us/step - loss: 0.0111 - acc: 0.92972s - loss: 0.011 - ETA: 1s - loss:\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0104 - acc: 0.9338\n",
      "10000/10000 [==============================] - 4s 352us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013915338389202952, 0.9064]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=8, batch_size=64)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 8 epochs, it took longer and didn't have as good of results as with binary_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 53s 886us/step - loss: 0.1675 - acc: 0.9209\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 52s 867us/step - loss: 0.1074 - acc: 0.9251\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 39s 655us/step - loss: 0.0938 - acc: 0.9258\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 49s 824us/step - loss: 0.0837 - acc: 0.9261\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 52s 869us/step - loss: 0.0783 - acc: 0.9253\n",
      "10000/10000 [==============================] - 4s 380us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07774323242306709, 0.9302000246047973]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the batch size to 128 while having the loss of binary_crossentropy showed a significant increase in accuracy.\n",
    "\n",
    "Do more epochs further improve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.1769 - acc: 0.9185\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 34s 563us/step - loss: 0.1125 - acc: 0.9234\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 34s 565us/step - loss: 0.0995 - acc: 0.9239\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.0880 - acc: 0.9244\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.0824 - acc: 0.9226\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 0.0781 - acc: 0.9234\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 33s 553us/step - loss: 0.0743 - acc: 0.9231\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 0.0693 - acc: 0.9216\n",
      "10000/10000 [==============================] - 2s 245us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0770086382329464, 0.920370026397705]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=8, batch_size=128)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more epochs actually made it worse by a percent."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
