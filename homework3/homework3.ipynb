{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "## CS 344\n",
    "## Elizabeth Koning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Creating a neural network for the XOR function is only possible for multi-layered neural networks with non-linear activation functions.\n",
    "\n",
    "With a single layered network, it is impossible. A neuron evaluation uses activations and weights to compare against an activation function, such as a threshold. With XOR, there is no single threshold that can include both true values and neither false. If the threshold includes both of the values we want to be true, it will give the same results as OR and the True, True case will be included. However, we cannot raise it higher because then we exclude both of the cases that we want to result in True.\n",
    "\n",
    "In short, XOR is not linearly separable, so no linear model can learn the XOR function.\n",
    "\n",
    "In class, we saw how we could do it with backpropogation or with a multiple layered network.\n",
    "\n",
    "With a multiple layered network using a step function, we can use AND and OR to get to XOR. It would look like:\n",
    "\n",
    "[TODO: include image]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "First, we need to load in the data set and import the applicable packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. We can compute the dimensions of the data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (404, 13)\n",
      "y_train shape:  (404,)\n",
      "x_test shape:   (102, 13)\n",
      "y_test shape:   (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape:  \", x_test.shape)\n",
    "print(\"y_test shape:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Next, we can create the testing, training, and validation sets. We already having testing and training sets, we just need to create a validation set as well.\n",
    "\n",
    "It could work well to have testing and validation datasets of the same size. Halving the testing set would leave us with only 51 examples for training and 51 for validation, so I'll take them from the training data.\n",
    "\n",
    "From looking at the Keras documentation, some of its methods do the training/validation split within the modeling function. Depending on what we were doing, we could have the option of telling Keras we want 20% of our training data to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (302, 13)\n",
      "y_train shape:  (302,)\n",
      "x_val shape:    (102, 13)\n",
      "y_val shape:    (102,)\n",
      "x_test shape:   (102, 13)\n",
      "y_test shape:   (102,)\n",
      "[1.2329e-01 0.0000e+00 1.0010e+01 0.0000e+00 5.4700e-01 5.9130e+00\n",
      " 9.2900e+01 2.3534e+00 6.0000e+00 4.3200e+02 1.7800e+01 3.9495e+02\n",
      " 1.6210e+01]\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[0:102]\n",
    "x_train = x_train[102:]\n",
    "y_val = y_train[0:102]\n",
    "y_train = y_train[102:]\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_val shape:   \", x_val.shape)\n",
    "print(\"y_val shape:   \", y_val.shape)\n",
    "print(\"x_test shape:  \", x_test.shape)\n",
    "print(\"y_test shape:  \", y_test.shape)\n",
    "\n",
    "print(x_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Next, we can create a synthetic feature that could be useful.\n",
    "\n",
    "From the Keras documentation, it is not clear what the features we already have are. I found a list here: https://www.kaggle.com/c/boston-housing\n",
    "\n",
    "One potentially useful synthetic feature would be multiplying \"rad\" (index of accessibility to radial highways) by \"dis\" (weighted mean of distances to five Boston employment centres) to get a more complete picture of the commuting and travel situation.\n",
    "\n",
    "\"rad\" is the ninth feature, and \"dis\" is the eighth, so if the order Kaggle lists matches the dataset, they will be using indices 7 and 8, and we want to put our synthetic feature in column 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n",
      "(1, 13)\n",
      "x_train shape:  (306, 13)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:][7].shape)\n",
    "print(x_train[])\n",
    "travel = x_train[7] * x_train[8]\n",
    "travel = travel.reshape(1,-1) # reshape to be one column\n",
    "print(travel.shape)\n",
    "x_train = np.append(x_train, travel, axis=0)\n",
    "print(\"x_train shape: \", x_train.shape)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
