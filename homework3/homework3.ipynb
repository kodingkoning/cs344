{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "## CS 344\n",
    "## Elizabeth Koning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Creating a neural network for the XOR function is only possible for multi-layered neural networks with non-linear activation functions.\n",
    "\n",
    "With a single layered network, it is impossible. A neuron evaluation uses activations and weights to compare against an activation function, such as a threshold. With XOR, there is no single threshold that can include both true values and neither false. If the threshold includes both of the values we want to be true, it will give the same results as OR and the True, True case will be included. However, we cannot raise it higher because then we exclude both of the cases that we want to result in True.\n",
    "\n",
    "In short, XOR is not linearly separable, so no linear model can learn the XOR function.\n",
    "\n",
    "In class, we saw how we could do it with backpropogation or with a multiple layered network.\n",
    "\n",
    "With a multiple layered network using a step function, we can use AND and OR to get to XOR. It would look like:\n",
    "\n",
    "![](https://lh3.googleusercontent.com/v1x38cgc3h1f10qMWvha68YlTgC5951PVFgXTkcjao4jDhQLt0FrWKk_FXW9porL-uEcpXFU9HYYd6A_Ou-SZ_VlLPSq8m5RPan6-LPIcXZ2ajF-slgBZCb_t8LVRZPZHp8GHP3EUwulyCJy6kaoz_usLWs5Z52QkCoh2sVuA9BATc2O_AH8Ys5PGZsJ2-984qhEfXSQYezQY-Ex6xmL_WBNvijNAvPmsns_LFNBMukvoydQoUe7PO68EPdhwz5jpgiHCezpxGrwXxrXuqeWOneny_lNc6yB-LkjbmBaF6FWBSkgioILIqn0LXTq9xF_LYLDc1COwF63ax-GMR1LutuuPPPEXh9hR0X-EGc2P128Muox6SnVFqDfEeKuXRw0UlWbeUC9yE5GreFGSD3Ac9WTWVt-BMzQyoKo3DSVdMnPzD2AM1EWufTde2aCeyDUvpaKJhlNqmNUbWCTiqSASRXCkkYLaxrrZpJ4nD9GKmUiUEIzqcXP1gbxwJj0WhF68yJz8lB-8cJlZcRwwEwkMNFoABsKntI2MWaaEQGPJ9hekVAKCMpnK9ZWdO1qsUL0B97w5SsoAXruOpvKXL5lTm7n158Hj7Pmx-A3DGLVA82i9Ug4g0R_t98va4pAi1FWdFBHs5i9hkpTfMkcTC8R1fGfJPfuMQTGy7M---X7uIhVmXwRNCf0uceEy7fPl4L3p-yA1M-pCqRMro1skNxc6059=w720-h959-no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "First, we need to load in the data set and import the applicable packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. We can compute the dimensions of the data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (404, 13)\n",
      "y_train shape:  (404,)\n",
      "x_test shape:   (102, 13)\n",
      "y_test shape:   (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape:  \", x_test.shape)\n",
    "print(\"y_test shape:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Next, we can create the testing, training, and validation sets. We already having testing and training sets, we just need to create a validation set as well.\n",
    "\n",
    "It could work well to have testing and validation datasets of the same size. Halving the testing set would leave us with only 51 examples for training and 51 for validation, so I'll take them from the training data instead.\n",
    "\n",
    "According to the Keras documentation, some of its methods do the training/validation split within the modeling function. Depending on what we were doing, we could also have the option of telling Keras we want 20% of our training data to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (302, 13)\n",
      "y_train shape:  (302,)\n",
      "x_val shape:    (102, 13)\n",
      "y_val shape:    (102,)\n",
      "x_test shape:   (102, 13)\n",
      "y_test shape:   (102,)\n",
      "[1.2329e-01 0.0000e+00 1.0010e+01 0.0000e+00 5.4700e-01 5.9130e+00\n",
      " 9.2900e+01 2.3534e+00 6.0000e+00 4.3200e+02 1.7800e+01 3.9495e+02\n",
      " 1.6210e+01]\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[0:102]\n",
    "x_train = x_train[102:]\n",
    "y_val = y_train[0:102]\n",
    "y_train = y_train[102:]\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_val   shape: \", x_val.shape)\n",
    "print(\"y_val   shape: \", y_val.shape)\n",
    "print(\"x_test  shape: \", x_test.shape)\n",
    "print(\"y_test  shape: \", y_test.shape)\n",
    "\n",
    "print(x_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Next, we can create a synthetic feature that could be useful.\n",
    "\n",
    "From the Keras documentation, it is not clear what the features we already have are. I found a list here: https://www.kaggle.com/c/boston-housing\n",
    "\n",
    "One potentially useful synthetic feature would be multiplying \"rad\" (index of accessibility to radial highways) by \"dis\" (weighted mean of distances to five Boston employment centres) to get a more complete picture of the commuting and travel situation. This would serve as an \"accessibility index\" in a way.\n",
    "\n",
    "One synthetic feature I considered including was whether it was build before or after lead paint became illegal. However, according to this (http://lib.stat.cmu.edu/datasets/boston), the data is from 1978, the same year that lead paint became illegal. This also would be less helpful in Boston than in other parts of the country because the area is so much older.\n",
    "\n",
    "I used help from this source in order to set the dataframe to have columns associated with names: https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.1866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT   travel  \n",
       "0     15.3  396.90   4.98   4.0900  \n",
       "1     17.8  396.90   9.14   9.9342  \n",
       "2     17.8  392.83   4.03   9.9342  \n",
       "3     18.7  394.63   2.94  18.1866  \n",
       "4     18.7  396.90   5.33  18.1866  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston_data = load_boston()\n",
    "boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names) # does not include MEDV, the target\n",
    "\n",
    "boston['travel'] = boston['RAD'] * boston['DIS']\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
